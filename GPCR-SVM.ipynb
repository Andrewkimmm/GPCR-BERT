{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewkim/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "252\n",
      "tensor([ 2,  6,  6, 14,  9,  8, 24,  8,  8,  7, 21,  7, 11,  8, 21, 10,  5, 11,\n",
      "         8,  5,  6, 11,  8, 19,  7, 17,  8,  5,  8, 11, 15,  6, 11,  6, 12, 19,\n",
      "         9, 13,  5, 18, 15,  8, 15, 17, 20, 19, 11, 15, 10,  5,  6, 23,  6, 14,\n",
      "         5,  8, 21,  7,  5,  6,  8,  8, 16, 19,  7,  6,  6, 23, 11,  5, 15, 12,\n",
      "        15, 24, 15, 19,  7, 17, 19, 24, 23,  9, 19, 24, 15, 10, 11, 14,  8,  5,\n",
      "        23,  8, 15,  6, 10, 11,  9, 15,  5, 23,  8,  1,  1,  1,  1,  1, 20, 19,\n",
      "         6, 11, 15, 10, 16, 19, 12, 20, 18, 10,  5,  5, 15, 12, 17, 12,  6, 13,\n",
      "         8, 11, 11,  5, 21,  8, 24, 11,  8, 10,  7,  5, 15, 10, 19,  5, 16, 11,\n",
      "        18, 21, 22, 24, 20, 13,  6, 15, 22, 18,  9,  6, 11, 17, 23, 20,  6,  9,\n",
      "         9, 15, 23, 23, 14, 19, 19, 15, 17, 18,  6, 20,  6, 11,  6, 10, 10, 11,\n",
      "         8, 10, 19, 20,  8, 16,  5,  8, 11, 21,  8, 19,  8, 20, 10, 13,  8, 19,\n",
      "        18,  9,  6, 12, 13, 18,  5, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 12, 19,  6,  5, 12,  9, 22, 12,  6,  5, 12, 15,  5,  7, 11,\n",
      "        11, 21,  7, 15, 19, 15,  5, 23, 24,  5, 16, 19, 19, 11,  8, 17, 11,  8,\n",
      "        22,  8, 11, 18, 14, 17,  5, 11, 13, 12,  9,  8, 20, 11,  5,  5, 17, 24,\n",
      "        11,  7, 20,  8, 17, 10,  7, 19, 17, 16,  5, 11, 20, 23, 13, 10, 16, 14,\n",
      "        19, 13, 11,  6, 19, 18,  9,  5,  5, 23,  5,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([11,  6,  8, 14, 13])\n"
     ]
    }
   ],
   "source": [
    "distance_mask_token = 0\n",
    "no_mask_token = 5\n",
    "max_len = 371\n",
    "bert_max_len = 373\n",
    "\n",
    "data2 = np.load('/home/andrewkim/Desktop/GPCRBert/data/final_mask5_class.npy', allow_pickle=True)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(data2.shape[0]):\n",
    "    seq = data2[i][1]\n",
    "    seq_join = ''.join(seq)\n",
    "\n",
    "    motif = data2[i][2] # req_pre\n",
    "    motif_join = ''.join(motif) # requ_pre_str\n",
    "    start_idx = seq_join.find(motif_join)\n",
    "\n",
    "    seq_list = list(seq_join)\n",
    "    seq_list[start_idx + distance_mask_token : start_idx + distance_mask_token + no_mask_token] = 'J' * no_mask_token\n",
    "    seq_list_spaced = ' '.join(seq_list)\n",
    "    label = motif_join[distance_mask_token: distance_mask_token + no_mask_token]\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert')\n",
    "    seq_tokenized = tokenizer(seq_list_spaced, return_tensors='pt', padding='max_length', max_length=bert_max_len)\n",
    "    label_spaced = ' '.join(motif_join)\n",
    "    label_tokenized = tokenizer(label_spaced, return_tensors='pt')\n",
    "\n",
    "    data.append(seq_tokenized['input_ids'][0])\n",
    "    labels.append(label_tokenized['input_ids'][0][1+distance_mask_token:1+distance_mask_token+no_mask_token]) #\n",
    "\n",
    "\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for output 1: 71.43%\n",
      "Accuracy for output 2: 60.32%\n",
      "Accuracy for output 3: 57.14%\n",
      "Accuracy for output 4: 61.90%\n",
      "Accuracy for output 5: 66.67%\n",
      "Total Accuracy for output: 63.49%\n"
     ]
    }
   ],
   "source": [
    "data_flattened = [item.numpy().flatten() for item in data]\n",
    "\n",
    "# Assume labels is your (2,) vector labels\n",
    "labels = np.array(labels)  # convert to numpy array if it's not already\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_flattened, labels, test_size=0.25, random_state=41)\n",
    "\n",
    "\n",
    "# Create and train the multi-output SVM model\n",
    "svm_model = svm.SVC()\n",
    "multi_output_svm = MultiOutputClassifier(svm_model)\n",
    "multi_output_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = multi_output_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model - you may need to define a suitable evaluation metric for your multi-output task\n",
    "# For simplicity, here we're using accuracy score which may or may not be suitable for your task\n",
    "accuracy_list = []\n",
    "for i in range(no_mask_token):\n",
    "    accuracy = accuracy_score(y_test[:, i], y_pred[:, i])\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(f'Accuracy for output {i + 1}: {accuracy * 100:.2f}%')\n",
    "\n",
    "print(f'Total Accuracy for output: {np.sum(accuracy_list) * 100/no_mask_token:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bindbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
